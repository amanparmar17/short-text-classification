{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BOW_MODEL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xbRSp22b5a9t"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HudM5hfCgpMz",
        "colab_type": "text"
      },
      "source": [
        "#MAJOR 2\n",
        "\n",
        "***### BAG OF WORDS ###***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzapwVWf6VOi",
        "colab_type": "code",
        "outputId": "910120cc-1cec-4f81-cc34-35ec080add7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install pickle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUu3I3qjgn-V",
        "colab_type": "code",
        "outputId": "810bcd89-fedf-46fd-c8ef-224be1551a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#mount the drive to colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtwQIfXGhK2d",
        "colab_type": "code",
        "outputId": "e97f8588-3c99-465c-8e32-9d48597ec5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "#checking the usage of gpus by colab\n",
        "\n",
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjtkVMRyhN3l",
        "colab_type": "code",
        "outputId": "003acb57-1b75-4e23-93a8-4d91eb1c0104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 3032150613692309798\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 14233700690669714090\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 98966261963422908\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 15956161332\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 13603419413933170078\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32jOkgQrimaQ",
        "colab_type": "text"
      },
      "source": [
        "importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlfbX2VZiPq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.linear_model import LogisticRegression as LR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra6bztUVC-HW",
        "colab_type": "text"
      },
      "source": [
        "importing and splitting the dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbwUAF2tDHMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#%% handlig the dataset with classes with less than 7000 instances each\n",
        "s\n",
        "dataset=dataset.dropna()\n",
        "X=dataset['text_instance']\n",
        "y=dataset['category']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKjtnXijDId1",
        "colab_type": "text"
      },
      "source": [
        "vectorising the data samples and fitting a  model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgBe9PfRDUWf",
        "colab_type": "code",
        "outputId": "0d39100e-ddd5-451b-f2f2-4e28f0602ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Vectorizing train...\")\n",
        "\n",
        "vectorizer = TfidfVectorizer( max_features = 40000, ngram_range = ( 1, 3 ), \n",
        "\tsublinear_tf = True )\n",
        "train_x = vectorizer.fit_transform( X_train )\n",
        "\n",
        "print(\"Vectorizing test...\")\n",
        "\n",
        "test_x = vectorizer.transform( X_test)\n",
        "\n",
        "print(\"Training...\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorizing train...\n",
            "Vectorizing test...\n",
            "Training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7vXj6buKfVb",
        "colab_type": "text"
      },
      "source": [
        "fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsj5rCsZKhJf",
        "colab_type": "code",
        "outputId": "2714b1fc-131d-4a91-e122-67e9058ccb32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "\n",
        "# using a simple logistic regression model to fit through the dataset\n",
        "model = LR()\n",
        "model.fit( train_x, y_train )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SJgZN39DTmt",
        "colab_type": "text"
      },
      "source": [
        "predicting from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gdUKpkSDYu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = model.predict_proba( test_x )[:,1] \n",
        "y_pred=model.predict(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBNaMKXZVQ81",
        "colab_type": "code",
        "outputId": "53e26b18-253d-4f91-824c-0e93bfd9dd82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy score: \",str(accuracy_score(y_test, y_pred)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.5340258071424747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbRSp22b5a9t",
        "colab_type": "text"
      },
      "source": [
        "#53.4% accuracy achieved with BOW "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oesd0UrU5sXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle \n",
        "\n",
        "# Save the trained model as a pickle string. \n",
        "# saved_model = pickle.dumps(model,\"model_BOW_less7000_25classes\") \n",
        "\n",
        "pickle.dump(model, open(\"model_BOW_less7000_25classes.sav\", 'wb'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_PI_n_fVWIw",
        "colab_type": "code",
        "outputId": "fd079944-b745-40c1-9e32-e0f8d2fcf6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pred[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['MEDIA', 'DIVORCE', 'RELIGION', 'WEIRD NEWS', 'MONEY'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa45j-o6Vbke",
        "colab_type": "code",
        "outputId": "113729ab-2a7e-4481-e492-13fd601e89bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "y_test[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5046          MEDIA\n",
              "90699       DIVORCE\n",
              "30914     WORLDPOST\n",
              "43396    WEIRD NEWS\n",
              "17987         STYLE\n",
              "Name: category, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm_EbO4YVfl2",
        "colab_type": "code",
        "outputId": "f84c9712-54bd-4246-eee2-3eadbd2a947d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_test[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5046     Woman's Elaborate Scheme To Discredit Washingt...\n",
              "90699    Why Dating And Men Are Better When You're A Si...\n",
              "30914    Rome is Berning! The Bromance Between Bernie a...\n",
              "43396             Covered Wagon Turns Over, Snarls Traffic\n",
              "17987                           No need to break the bank.\n",
              "Name: text_instance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLnA4KdG2xk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDHQ42s9Vmk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyRAy5BioXrE",
        "colab_type": "text"
      },
      "source": [
        "#Bag of words validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWvURMyPotg_",
        "colab_type": "text"
      },
      "source": [
        "code to increase the allotted ram from 12GB to 25GB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ksmwIFWqoVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while(1):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coqfxSSBoqSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.metrics import roc_auc_score as AUC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orJkqPQFp3VW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_file = \"/content/drive/My Drive/MAJOR 2- WORK IN PROGRESS/dataset_25classes_less7000.csv\"\n",
        "\n",
        "data = pd.read_csv( data_file)\n",
        "data=data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t0VHH4wCOBY",
        "colab_type": "text"
      },
      "source": [
        "preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m3TY6gCCMpu",
        "colab_type": "code",
        "outputId": "e1077e80-7215-4025-e3e6-50a1b209c1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "print(data.shape)\n",
        "\n",
        "print(data.columns)\n",
        "print(data['category'].unique())\n",
        "print()\n",
        "print(data['category'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(93384, 3)\n",
            "Index(['Unnamed: 0', 'text_instance', 'category'], dtype='object')\n",
            "['CRIME' 'WORLD NEWS' 'IMPACT' 'WEIRD NEWS' 'WOMEN' 'MEDIA' 'TECH'\n",
            " 'RELIGION' 'SCIENCE' 'LATINO VOICES' 'EDUCATION' 'COLLEGE'\n",
            " 'ARTS & CULTURE' 'STYLE' 'GREEN' 'TASTE' 'GOOD NEWS' 'WORLDPOST' 'FIFTY'\n",
            " 'ARTS' 'DIVORCE' 'MONEY' 'ENVIRONMENT' 'CULTURE & ARTS']\n",
            "\n",
            "DIVORCE           6852\n",
            "WOMEN             6592\n",
            "IMPACT            6520\n",
            "CRIME             6080\n",
            "MEDIA             5088\n",
            "WEIRD NEWS        4879\n",
            "GREEN             4668\n",
            "RELIGION          4413\n",
            "WORLD NEWS        4352\n",
            "TECH              4163\n",
            "TASTE             4036\n",
            "SCIENCE           3953\n",
            "STYLE             3821\n",
            "WORLDPOST         3820\n",
            "MONEY             3413\n",
            "ARTS & CULTURE    2678\n",
            "ENVIRONMENT       2644\n",
            "FIFTY             2443\n",
            "GOOD NEWS         2437\n",
            "ARTS              2372\n",
            "LATINO VOICES     2150\n",
            "COLLEGE           2065\n",
            "CULTURE & ARTS    2049\n",
            "EDUCATION         1896\n",
            "Name: category, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-qqdxaSC1Xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# after analysing the classses: combining some of the spearate classes into one\n",
        "\n",
        "\n",
        "#weird new + world news + good news= news\n",
        "#CULTURE & ARTS + ARTS & CULTURE == ARTS & CULTURE\n",
        "#tech + science = science and tech\n",
        "#green+environment= environment\n",
        "#REMOVE LATINO VOICES AND FIFTY\n",
        "#college +education = education & college\n",
        "\n",
        "\n",
        "data['category'].replace({\"COLLEGE\":\"COLLEGE & EDUCATION\",\"EDUCATION\":\"COLLEGE & EDUCATION\",\n",
        "                          \"GREEN\":\"ENVIRONMENT\",\"TECH\":\"TECH & SCIENCE\",\"SCIENCE\":\"TECH & SCIENCE\",\n",
        "                          \"CULTURE & ARTS\":\"ARTS & CULTURE\",\"WEIRD NEWS\":\"NEWS\",\"GOOD NEWS\":\"NEWS\",\"WORLD NEWS\":\"NEWS\",\"ARTS\":\"ARTS & CULTURE\"}, inplace=True)\n",
        "\n",
        "removed_classes=[\"LATINO VOICES\",\"FIFTY\"]\n",
        "data=data[~data['category'].isin(removed_classes)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGWs9Yej42Ho",
        "colab_type": "code",
        "outputId": "d52acf75-359c-4065-9bf0-5aebfcb237d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(len(data['category'].unique()))\n",
        "print(data['category'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "NEWS                   11668\n",
            "TECH & SCIENCE          8116\n",
            "ENVIRONMENT             7312\n",
            "ARTS & CULTURE          7099\n",
            "DIVORCE                 6852\n",
            "WOMEN                   6592\n",
            "IMPACT                  6520\n",
            "CRIME                   6080\n",
            "MEDIA                   5088\n",
            "RELIGION                4413\n",
            "TASTE                   4036\n",
            "COLLEGE & EDUCATION     3961\n",
            "STYLE                   3821\n",
            "WORLDPOST               3820\n",
            "MONEY                   3413\n",
            "Name: category, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY6K8wtQ8TEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_original=data.copy()\n",
        "train_i_original, test_i_original = train_test_split( np.arange( len( data_original )), train_size = 0.8, random_state = 44 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meSMYYCzA7iF",
        "colab_type": "code",
        "outputId": "b49e6098-87e1-42c0-ebbc-1bc9d0100c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(data_original.head(2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0                                      text_instance category\n",
            "0           0  There Were 2 Mass Shootings In Texas Last Week...    CRIME\n",
            "1           1  She left her husband. He killed their children...    CRIME\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM3N3--b8BXX",
        "colab_type": "code",
        "outputId": "2a7e2f10-5bbc-43c0-b7c2-4513369a76ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "factor = pd.factorize(data['category'])\n",
        "data.category = factor[0]\n",
        "definitions = factor[1]\n",
        "\n",
        "\n",
        "print(len(factor))\n",
        "print(factor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "(array([0, 0, 1, ..., 5, 5, 5]), Index(['CRIME', 'NEWS', 'IMPACT', 'WOMEN', 'MEDIA', 'TECH & SCIENCE',\n",
            "       'RELIGION', 'COLLEGE & EDUCATION', 'ARTS & CULTURE', 'STYLE',\n",
            "       'ENVIRONMENT', 'TASTE', 'WORLDPOST', 'DIVORCE', 'MONEY'],\n",
            "      dtype='object'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Tz7LjK6RhP",
        "colab_type": "code",
        "outputId": "d98d593a-1ee6-49e6-da8e-d854eda7586f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(data.category[:5])\n",
        "print(definitions)\n",
        "print(len(definitions))\n",
        "print(data.category[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    1\n",
            "4    2\n",
            "Name: category, dtype: int64\n",
            "Index(['CRIME', 'NEWS', 'IMPACT', 'WOMEN', 'MEDIA', 'TECH & SCIENCE',\n",
            "       'RELIGION', 'COLLEGE & EDUCATION', 'ARTS & CULTURE', 'STYLE',\n",
            "       'ENVIRONMENT', 'TASTE', 'WORLDPOST', 'DIVORCE', 'MONEY'],\n",
            "      dtype='object')\n",
            "15\n",
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    1\n",
            "4    2\n",
            "Name: category, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EW5HXc9-M0f",
        "colab_type": "code",
        "outputId": "4739ff3a-3f45-4ee1-8086-03b638f931bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(data.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0                                      text_instance  category\n",
            "0           0  There Were 2 Mass Shootings In Texas Last Week...         0\n",
            "1           1  She left her husband. He killed their children...         0\n",
            "2          22  South Korean President Meets North Korea's Kim...         1\n",
            "3          23  The two met to pave the way for a summit betwe...         1\n",
            "4          24  With Its Way Of Life At Risk, This Remote Oyst...         2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37SoN3AVXzDG",
        "colab_type": "code",
        "outputId": "c1326643-243c-493a-87a3-caa936518095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(data['category'].unique()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LECfz3o63Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_i, test_i = train_test_split( np.arange( len( data )), train_size = 0.8, random_state = 44 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKAEn9r4GTQz",
        "colab_type": "code",
        "outputId": "a7d000f5-f358-4197-a594-1a4a29bae993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(train_i.shape)\n",
        "print(test_i.shape)\n",
        "\n",
        "\n",
        "print(train_i_original.shape)\n",
        "print(test_i_original.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(71032,)\n",
            "(17759,)\n",
            "(71032,)\n",
            "(17759,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5yNu-O18aX8",
        "colab_type": "code",
        "outputId": "d010b5ba-e4d3-49e2-8326-c83036833ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_i[:2])\n",
        "print(train_i_original[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[86120 13936]\n",
            "[86120 13936]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekb4dlPYGsM2",
        "colab_type": "code",
        "outputId": "cf148a7f-4d3d-4042-ff32-31642399537d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_i[:5]\n",
        "print(train_i[1])\n",
        "print(data.iloc[train_i[1]])\n",
        "\n",
        "print(train_i_original[1])\n",
        "print(data_original.iloc[train_i_original[1]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13936\n",
            "Unnamed: 0                                                   53882\n",
            "text_instance    Billionaire Cash Is Flooding Los Angeles To Pu...\n",
            "category                                                         7\n",
            "Name: 14496, dtype: object\n",
            "13936\n",
            "Unnamed: 0                                                   53882\n",
            "text_instance    Billionaire Cash Is Flooding Los Angeles To Pu...\n",
            "category                                       COLLEGE & EDUCATION\n",
            "Name: 14496, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ4z7l-Gp-FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data.iloc[train_i]\n",
        "test = data.iloc[test_i]\n",
        "\n",
        "train=train.dropna()\n",
        "test=test.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGKCtF6Gsj8J",
        "colab_type": "code",
        "outputId": "a2660503-bc7b-4ec9-9620-322a8b170a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(test[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Unnamed: 0                                      text_instance  category\n",
            "50646      181646           China Making Some Missiles More Powerful        12\n",
            "33658      132224  Richard Branson Returns To Passenger Space Tra...         5\n",
            "33922      133194  Homeless Shelter Pods Provide Night's Rest, Ca...         2\n",
            "93383      348444  Mitt Romney's Project ORCA Failure: Broken ORC...         5\n",
            "63119      210174  What Happens When 5 Street Artists Share A Wal...         8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaPN_Y6FG8u4",
        "colab_type": "code",
        "outputId": "89d162d5-a0b0-40ee-eb4e-d490a658b545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "print(train.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(71032, 3)\n",
            "(17759, 3)\n",
            "Index(['Unnamed: 0', 'text_instance', 'category'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ANsbxjoqASE",
        "colab_type": "code",
        "outputId": "f6148480-d4af-470b-cb8a-81b7afc57e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Creating the bag of words...\\n\")\n",
        "\n",
        "vectorizer = CountVectorizer( analyzer = \"word\", tokenizer = None, preprocessor = None, \n",
        "\tstop_words = None, max_features = 5000 )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating the bag of words...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ENP5V7WqDNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_features = vectorizer.fit_transform(train['text_instance'])\n",
        "train_data_features = train_data_features.toarray()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K343QpMRHhrV",
        "colab_type": "code",
        "outputId": "c1dce7d4-ab58-4625-f103-56590c9c314c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(train_data_features))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSfv048fHHfZ",
        "colab_type": "code",
        "outputId": "7efff70b-e817-408a-e952-21aa89d67672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(type(train_data_features))\n",
        "\n",
        "print(train_data_features[:5])\n",
        "\n",
        "print(len(train_data_features[0]))\n",
        "\n",
        "print(np.unique(train_data_features[:5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "5000\n",
            "[0 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm_viaG1qFCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # test features\n",
        "\n",
        "# # Create an empty list and append the clean reviews one by one\n",
        "# clean_test_reviews = []\n",
        "\n",
        "# print(\"Cleaning and parsing the test set movie reviews...\\n\")\n",
        "\n",
        "# skip=0\n",
        "# for review in test['text_instance']:\n",
        "#     try:\n",
        "#         clean_test_reviews.append( \" \".join( KaggleWord2VecUtility.review_to_wordlist( review, True )))\n",
        "#     except:\n",
        "#         skip+=1\n",
        "# print(skip)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF72uKIwqOAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Get a bag of words for the test set, and convert to a numpy array\n",
        "test_data_features = vectorizer.transform( test['text_instance'] )\n",
        "test_data_features = test_data_features.toarray()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EK7b1w6qSY6",
        "colab_type": "code",
        "outputId": "9c25b82c-a971-46c0-b5a8-c1b8a9b6b2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#%%\n",
        "###\n",
        "\n",
        "print(\"Training the random forest (this may take a while)...\")\n",
        "\n",
        "forest = RandomForestClassifier( n_estimators = 100, n_jobs = -1, verbose = 1 )\n",
        "forest = forest.fit( train_data_features, train[\"category\"] )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the random forest (this may take a while)...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  9.2min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WysP2G0ifBva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the model for further use in the future after the session expires??\n",
        "import pickle\n",
        "\n",
        "pickle.dump(forest, open(\"model_BOW_RF_less7000_24classes_REFINED.pkl\", 'wb'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvsCHXiiopXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the model to use\n",
        "import pickle \n",
        "\n",
        "filename=\"/content/drive/My Drive/MAJOR 2- WORK IN PROGRESS/model_BOW_RF_less7000_24classes_REFINED.pkl\"\n",
        "fileopen=open(filename,\"rb\")\n",
        "forest=pickle.load(fileopen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ4yav9ECz2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import os\n",
        "\n",
        "newpath=\"/content/model_BOW_RF_less7000_24classes_REFINED.pkl\"\n",
        "filename=newpath\n",
        "\n",
        "import pickle\n",
        "fileopen=open(filename,\"rb\")\n",
        "model=pickle.load(fileopen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkk2_OSfDCg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(model,open(\"/content/drive/My Drive/MAJOR 2- WORK IN PROGRESS/model_BOW_RF_less7000_24classes_REFINED.pkl\",\"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kqnMa6mFziC",
        "colab_type": "code",
        "outputId": "cd025fd0-19bf-4ce5-f334-7dc7c3d34cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "forest=model\n",
        "print(\"Predicting test labels...\\n\")\n",
        "rf_p = forest.predict_proba( test_data_features )\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting test labels...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    3.4s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYI7zcMoVfTM",
        "colab_type": "code",
        "outputId": "1db1c6e4-cd12-4e09-feff-14fe7d152657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(type(rf_p))\n",
        "print(rf_p[0,1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "0.1106031746031746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_woqsIlYL4j",
        "colab_type": "code",
        "outputId": "6ea0e1f7-dd60-4145-8374-bea1d6bcf406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(rf_p[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.11060317 0.         0.02       0.08       0.02\n",
            "  0.         0.06       0.03       0.         0.06527778 0.04\n",
            "  0.01       0.03       0.01       0.04771825 0.         0.13\n",
            "  0.02       0.         0.0360119  0.16038889 0.03       0.1       ]\n",
            " [0.02       0.01       0.01       0.04       0.02       0.03\n",
            "  0.         0.01       0.         0.01       0.02       0.04\n",
            "  0.         0.03       0.01       0.57       0.03       0.03\n",
            "  0.         0.01       0.01       0.04       0.04       0.02      ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.01       0.         0.         0.03       0.\n",
            "  0.         0.         0.         0.         0.92       0.\n",
            "  0.         0.         0.04       0.         0.         0.        ]\n",
            " [0.         0.01       0.         0.01       0.         0.01\n",
            "  0.01       0.         0.         0.         0.08       0.\n",
            "  0.02       0.43       0.         0.01       0.         0.\n",
            "  0.         0.         0.09       0.02       0.3        0.01      ]\n",
            " [0.         0.01       0.01       0.         0.01       0.01\n",
            "  0.         0.03       0.02       0.05       0.07       0.16\n",
            "  0.01       0.02       0.         0.01       0.04       0.03\n",
            "  0.37       0.01       0.02       0.02       0.05       0.05      ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqkXbgdm89YG",
        "colab_type": "code",
        "outputId": "b5acde5c-8a86-46fb-ef9b-40ec6cfda4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.argmax(rf_p[0]))   #finding the index of the maximum entry of the numpy array so as to map back to the original class"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueZsx0NdeOlA",
        "colab_type": "code",
        "outputId": "dfdd208c-992c-4378-b140-d86685f6b16b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#in the abovce output, each ofthe instance has been classified into 24 classes \n",
        "# to chekc if the distribution is sigmodial in fashio i.e sum=1\n",
        "\n",
        "print(np.sum(rf_p[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtftvF7OpG_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to find the class of the predicted instances\n",
        "\n",
        "#find the index of the maximum element from the numpy array\n",
        "#create a hashmap or simple map to map all the classes to the index numbers \n",
        "\n",
        "#once the whole dictionry is fromed\n",
        "\n",
        "#run through each of the predicted instance and find the maximumm element along witht he probalility saved separately in a list\n",
        "\n",
        "#combine the results from both the y_pred and y_test_original to match and finally find the accuracy of the model\n",
        "\n",
        "\n",
        "reversefactor = dict(zip(range(24),definitions))\n",
        "# y_test = np.vectorize(reversefactor.get)(test['category'])\n",
        "\n",
        "\n",
        "category_index=[]\n",
        "for i in rf_p:\n",
        "    index=np.argmax(i)\n",
        "    category_index.append(index)\n",
        "\n",
        "\n",
        "y_pred = np.vectorize(reversefactor.get)(category_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scBydqje_Nd9",
        "colab_type": "code",
        "outputId": "47cf1fc4-55dc-4ff4-920d-6c1040b6447f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(reversefactor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'CRIME', 1: 'WORLD NEWS', 2: 'IMPACT', 3: 'WEIRD NEWS', 4: 'WOMEN', 5: 'MEDIA', 6: 'TECH', 7: 'RELIGION', 8: 'SCIENCE', 9: 'LATINO VOICES', 10: 'EDUCATION', 11: 'COLLEGE', 12: 'ARTS & CULTURE', 13: 'STYLE', 14: 'GREEN', 15: 'TASTE', 16: 'GOOD NEWS', 17: 'WORLDPOST', 18: 'FIFTY', 19: 'ARTS', 20: 'DIVORCE', 21: 'MONEY', 22: 'ENVIRONMENT', 23: 'CULTURE & ARTS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRp9xX1l92Ju",
        "colab_type": "code",
        "outputId": "744a0926-4383-45b9-cc77-d50734a98579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(y_test[:5])\n",
        "\n",
        "print(category_index[:5])\n",
        "\n",
        "print(y_pred[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None None None None None]\n",
            "[21, 15, 16, 13, 18]\n",
            "['MONEY' 'TASTE' 'GOOD NEWS' 'STYLE' 'FIFTY']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4r_QIyo_onE",
        "colab_type": "code",
        "outputId": "f513586c-dc31-4866-f3d0-09943eea1a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(pd.crosstab(test['category'], y_pred, rownames=['Actual class'], colnames=['Predicted class']))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted class  ARTS  ARTS & CULTURE  COLLEGE  ...  WOMEN  WORLD NEWS  WORLDPOST\n",
            "Actual class                                    ...                              \n",
            "ARTS               10               0       48  ...     30          38         27\n",
            "ARTS & CULTURE     15               3       36  ...     17          73         34\n",
            "COLLEGE             8               1       30  ...      1           3          5\n",
            "CRIME              11               3       46  ...      7           1         11\n",
            "CULTURE & ARTS      3               1       27  ...    115          11         16\n",
            "DIVORCE            17               2       41  ...      3           4         15\n",
            "EDUCATION           7               2       42  ...      0           1          6\n",
            "ENVIRONMENT         9               2       57  ...     10           4          9\n",
            "FIFTY               9               3       55  ...      3           4         15\n",
            "GOOD NEWS           9               2       53  ...      3           9         29\n",
            "GREEN              14               1      103  ...      9           6         11\n",
            "IMPACT             26               5      490  ...      5          13         29\n",
            "LATINO VOICES      15             116       34  ...      2           5         22\n",
            "MEDIA              34               8       45  ...      3           5         31\n",
            "MONEY              28               2       53  ...      8           2         14\n",
            "RELIGION            6               4       76  ...      3          10         15\n",
            "SCIENCE            17               0       44  ...      4           9         19\n",
            "STYLE              23               5       31  ...      4          10        352\n",
            "TASTE              27               4       41  ...      4           6         40\n",
            "TECH              380               3       60  ...      2           7         33\n",
            "WEIRD NEWS         26               2       29  ...      9          12         68\n",
            "WOMEN              20               4       90  ...      9          15         54\n",
            "WORLD NEWS          8               6       44  ...      3           7         10\n",
            "WORLDPOST          18               5       72  ...      7           5         12\n",
            "\n",
            "[24 rows x 24 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2W2fFOHAYKa",
        "colab_type": "code",
        "outputId": "2fd5a99b-3ccd-4885-9625-30041c209725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#finding the accuracy of the model\n",
        "\n",
        "correct=0\n",
        "total=len(test['category'])\n",
        "skipped=0\n",
        "\n",
        "for i in range(0,len(y_pred)):\n",
        "    try:\n",
        "        if y_pred[i]==test['category'][i]:\n",
        "            correct+=1\n",
        "    except:\n",
        "        skipped+=1\n",
        "\n",
        "\n",
        "print(\"number of skipped instances: \",skipped)\n",
        "\n",
        "\n",
        "accuracy=correct/total\n",
        "\n",
        "print(\"the accuracy of the model is found out to be: \",accuracy)\n",
        "print(correct)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of skipped instances:  14989\n",
            "the accuracy of the model is found out to be:  0.006585640092091878\n",
            "123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYabrpKwVblp",
        "colab_type": "code",
        "outputId": "d02b50ff-c1f1-4a66-dd70-b6decac6b8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "auc = AUC( test['category'].values, rf_p[:,1] )\n",
        "print(\"random forest AUC:\", auc)\n",
        "\n",
        "# a random score from a _random_ forest\n",
        "# AUC: 0.919056767104\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-342d1b755fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"random forest AUC:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# a random score from a _random_ forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# AUC: 0.919056767104\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    379\u001b[0m                              \"instead\".format(max_fpr))\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[1;32m    383\u001b[0m                                          multi_class, average, sample_weight)\n",
            "\u001b[0;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBDWehS0qVnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# let's define a helper function\n",
        "\n",
        "def train_and_eval_auc( model, train_x, train_y, test_x, test_y ):\n",
        "\tmodel.fit( train_x, train_y )\n",
        "\tp = model.predict_proba( test_x )\n",
        "\tauc = AUC( test_y, p[:,1] )\n",
        "\treturn auc\n",
        "\n",
        "#\n",
        "\n",
        "lr = LR()\n",
        "auc = train_and_eval_auc( lr, train_data_features, train[\"sentiment\"], \\\n",
        "\ttest_data_features, test[\"sentiment\"].values )\n",
        "print(\"logistic regression AUC:\", auc)\n",
        "\n",
        "# logistic regression AUC: 0.925748792247\n",
        "# logistic regression AUC: 0.928301070895\t# different split\n",
        "\n",
        "\n",
        "# train a random forest ten times, average the scores\n",
        "\n",
        "rf_aucs = []\n",
        "for i in range( 10 ):\n",
        "\tauc = train_and_eval_auc( forest, train_data_features, train[\"sentiment\"], \\\n",
        "\t\ttest_data_features, test[\"sentiment\"].values )\n",
        "\t\n",
        "\tprint(\"random forest run {}, AUC: {}\".format( i, auc ))\n",
        "\trf_aucs.append( auc )\n",
        "\t\n",
        "avg_auc = sum( rf_aucs ) / len( rf_aucs )\n",
        "print(\"Average AUC from random forest:\", avg_auc)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3v43x8JHrJm",
        "colab_type": "text"
      },
      "source": [
        "#part 3 of bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3px4qKNJMtH",
        "colab_type": "text"
      },
      "source": [
        "***improved BOW validation script***\n",
        "***changes: leave stopwords in, use TF-IDF vectorizer, removed converting vectorizer output to np.array***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwIA26qYHtj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.metrics import roc_auc_score as AUC\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPOkC-y3IxLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_file = '/content/drive/My Drive/MAJOR 2- WORK IN PROGRESS/dataset_25classes_less7000.csv'\n",
        "data = pd.read_csv( data_file )\n",
        "\n",
        "train_i, test_i = train_test_split( np.arange( len( data )), train_size = 0.8, random_state = 44 )\n",
        "\n",
        "train = data.ix[train_i]\n",
        "test = data.ix[test_i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYPilc_EJe6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#handling the preprocessing of the imported data file once again\n",
        "\n",
        "print(data.shape)\n",
        "print(data['category'].value_count())\n",
        "\n",
        "\n",
        "#removing the classes and combining some into a single class \n",
        "\n",
        "# after analysing the classses: combining some of the spearate classes into one\n",
        "\n",
        "\n",
        "#weird new + world news + good news= news\n",
        "#CULTURE & ARTS + ARTS & CULTURE == ARTS & CULTURE\n",
        "#tech + science = science and tech\n",
        "#green+environment= environment\n",
        "#REMOVE LATINO VOICES AND FIFTY\n",
        "#college +education = education & college\n",
        "\n",
        "\n",
        "data['category'].replace({\"COLLEGE\":\"COLLEGE & EDUCATION\",\"EDUCATION\":\"COLLEGE & EDUCATION\",\n",
        "                          \"GREEN\":\"ENVIRONMENT\",\"TECH\":\"TECH & SCIENCE\",\"SCIENCE\":\"TECH & SCIENCE\",\n",
        "                          \"CULTURE & ARTS\":\"ARTS & CULTURE\",\"WEIRD NEWS\":\"NEWS\",\"GOOD NEWS\":\"NEWS\",\"WORLD NEWS\":\"NEWS\",\"ARTS\":\"ARTS & CULTURE\"}, inplace=True)\n",
        "\n",
        "removed_classes=[\"LATINO VOICES\",\"FIFTY\"]\n",
        "data=data[~data['category'].isin(removed_classes)]\n",
        "\n",
        "data_original=data.copy()\n",
        "train_i_original, test_i_original = train_test_split( np.arange( len( data_original )), train_size = 0.8, random_state = 44 )\n",
        "\n",
        "## factorize the category column of the dataset as a part of one hot encoding\n",
        "\n",
        "factor = pd.factorize(data['category'])\n",
        "data.category = factor[0]\n",
        "definitions = factor[1]\n",
        "\n",
        "\n",
        "print(len(factor))\n",
        "print(factor)\n",
        "\n",
        "#slitting the dataset into train and test dataset , first using the index of the instances and the allocating the rows to the defined dataset\n",
        "\n",
        "train_i, test_i = train_test_split( np.arange( len( data )), train_size = 0.8, random_state = 44 )\n",
        "\n",
        "train = data.iloc[train_i]\n",
        "test = data.iloc[test_i]\n",
        "\n",
        "train=train.dropna()\n",
        "test=test.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "513cLfBC40QA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# factorize the category column of the dataset \n",
        "\n",
        "print(\"Vectorizing...\")\n",
        "\n",
        "vectorizer = TfidfVectorizer( max_features = 40000, ngram_range = ( 1, 3 ), \n",
        "\tsublinear_tf = True )\n",
        "\n",
        "train_data_features = vectorizer.fit_transform( train )\n",
        "test_data_features = vectorizer.transform( train )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvNbtAwG6dl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fitting the model and predicting and finding the accuracy of the model\n",
        "\n",
        "\n",
        "lr = LR()\n",
        "\n",
        "lr.fit(train['test_instance'],train['category'])\n",
        "p=lr.predict(test['test_instance'])\n",
        "\n",
        "\n",
        "import keras\n",
        "\n",
        "accuracy=keras.metrics.categorical_accuracy(test['category'], p)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbYRXP1y6zCy",
        "colab_type": "text"
      },
      "source": [
        "#part 4: bag of words\n",
        "\n",
        "\n",
        "fofe remaining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrT1tY-h65VP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.metrics import roc_auc_score as AUC\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMIXG-t_-CsM",
        "colab_type": "text"
      },
      "source": [
        "https://wiki.eecs.yorku.ca/lab/MLL/projects:fofe:start\n",
        "\n",
        "fofe information"
      ]
    }
  ]
}